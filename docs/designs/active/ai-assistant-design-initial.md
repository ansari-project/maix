# AI Assistant with MCP Integration - Implementation Design (Initial)

## Status: DESIGN PHASE (INITIAL - Before Comments)
**Date**: January 10, 2025
**Author**: Claude Code

---

## 1. DESIGN PHASE - MCP-Integrated Architecture

### 1.1 Overview
Transform the current AI Assistant stub into a fully functional, context-aware assistant powered by Google Gemini that **leverages the existing MCP tools** for all data operations. The AI Assistant becomes a natural language interface to the MCP server, allowing users to interact with Maix through conversation rather than API calls.

### 1.2 Core Architecture Decision

**SELECTED APPROACH: Hybrid MCP + Direct Gemini**

The AI Assistant will:
1. Use **Gemini directly** for natural language understanding and generation
2. Execute actions through **existing MCP tools** (no duplicate API endpoints)
3. Leverage **PAT infrastructure** for secure MCP access
4. Follow the **Event Assistant pattern** already established in `/api/chat/events`

### 1.3 Architecture Flow

```
User Input → AI Assistant UI → /api/ai/chat endpoint
                                        ↓
                              Parse intent with Gemini
                                        ↓
                            Execute via MCP tools (using PAT)
                                        ↓
                              Format response with Gemini
                                        ↓
                                  Return to UI
```

### 1.4 PAT Management Strategy

Based on the Event Manager implementation:

#### Automatic PAT Generation
```typescript
// Reuse pattern from pat-manager.service.ts
export async function getOrCreateAIAssistantPat(userId: string) {
  // Check for existing AI Assistant PAT
  const existing = await prisma.personalAccessToken.findFirst({
    where: {
      userId,
      name: 'AI Assistant (Auto-generated)',
      revokedAt: null,
      expiresAt: { gt: new Date() }
    }
  })
  
  if (existing) {
    return { token: existing, plainToken: null }
  }
  
  // Create new PAT with 90-day expiry
  const plainToken = generateSecureToken()
  const hashedToken = await hashToken(plainToken)
  
  const token = await prisma.personalAccessToken.create({
    data: {
      userId,
      name: 'AI Assistant (Auto-generated)',
      hashedToken,
      expiresAt: addDays(new Date(), 90),
      metadata: { autoGenerated: true, purpose: 'ai-assistant' }
    }
  })
  
  return { token, plainToken }
}
```

### 1.5 MCP Tool Integration

#### Available MCP Tools for AI Assistant

**Content Management**:
- `maix_manage_post` - Create questions, answers, updates
- `maix_search_posts` - Find existing content
- `maix_manage_comment` - Add comments
- `maix_search_comments` - Find discussions

**Project Management**:
- `maix_manage_project` - CRUD operations on projects
- `maix_search_projects` - Find projects
- `maix_manage_todo` - Task management
- `maix_search_todos` - Find tasks

**Product Management**:
- `maix_manage_product` - Product operations
- `maix_search_products` - Find products

**Organization Management**:
- `maix_manage_organization` - Org operations
- `maix_manage_organization_member` - Member management

**User Management**:
- `maix_update_profile` - Update user profile
- `maix_manage_personal_project` - Personal projects

### 1.6 Gemini Integration with MCP

#### Tool Calling Strategy

**Option 1: Gemini Function Calling → MCP Tools** ❌
- Complex mapping layer
- Double abstraction

**Option 2: Intent Detection → Direct MCP Calls** ✅ (SELECTED)
```typescript
// Parse user intent with Gemini
const intent = await parseIntent(userMessage)

// Map to MCP tool
switch(intent.action) {
  case 'create_project':
    return await mcpClient.call('maix_manage_project', {
      name: intent.name,
      description: intent.description
    })
}
```

**Option 3: Hybrid with Tool Descriptions** ✅ (RECOMMENDED)
```typescript
// Provide MCP tool descriptions to Gemini
const systemPrompt = `
You are an AI assistant for Maix. You can perform these actions:

PROJECTS:
- Create project: Use when user wants to start a new project
- Search projects: Use when user wants to find existing projects

Respond with JSON: {
  "action": "tool_name",
  "parameters": { ... },
  "explanation": "What you're doing"
}
`
```

### 1.7 Conversation Management

```typescript
interface AIConversation {
  id: string
  userId: string
  messages: AIMessage[]
  metadata: {
    startedAt: Date
    lastActiveAt: Date
    context?: any
  }
}
```

### 1.8 API Endpoint Design

```typescript
export async function POST(request: NextRequest) {
  // 1. Authenticate user
  const session = await getServerSession(authOptions)
  if (!session) return unauthorized()
  
  // 2. Get or create PAT for MCP access
  const { token, plainToken } = await getOrCreateAIAssistantPat(session.user.id)
  
  // 3. Initialize MCP client with PAT
  const mcpClient = createMcpClient({
    baseUrl: process.env.NEXT_PUBLIC_URL + '/api/mcp',
    token: plainToken || await decryptToken(token.encryptedToken)
  })
  
  // 4. Parse user message
  const { message, conversationId } = await request.json()
  
  // 5. Enrich with context from MCP
  const context = await enrichContext(mcpClient, session.user.id)
  
  // 6. Generate AI response
  const result = await genAI.models.generateContent({
    model: 'gemini-2.0-flash',
    contents: enrichedPrompt,
    generationConfig: {
      temperature: 0.7,
      maxOutputTokens: 2048,
    }
  })
  
  // 7. Parse AI response and execute MCP tools if needed
  const aiResponse = parseAIResponse(result.text)
  
  if (aiResponse.action) {
    const toolResult = await mcpClient.call(aiResponse.action, aiResponse.parameters)
    aiResponse.result = toolResult
  }
  
  return NextResponse.json(aiResponse)
}
```

### 1.9 Security Considerations

#### PAT Security
1. **Automatic PATs are encrypted** - Use existing encryption service
2. **Never expose PATs to client** - Server-side only
3. **Auto-expire after 90 days** - With renewal logic
4. **Separate from user PATs** - Different naming convention
5. **Audit trail** - Log all MCP operations

#### Prompt Injection Prevention
```typescript
const sanitizeUserInput = (input: string): string => {
  // Remove potential injection attempts
  const cleaned = input
    .replace(/system:/gi, '')
    .replace(/assistant:/gi, '')
    .replace(/\[INST\]/gi, '')
    .slice(0, 1000) // Limit length
  
  return cleaned
}
```

#### Rate Limiting
```typescript
// Per-user rate limits
const rateLimiter = new Map<string, { count: number, resetAt: Date }>()

const checkRateLimit = (userId: string): boolean => {
  const limit = rateLimiter.get(userId)
  const now = new Date()
  
  if (!limit || limit.resetAt < now) {
    rateLimiter.set(userId, {
      count: 1,
      resetAt: new Date(now.getTime() + 60000) // 1 minute window
    })
    return true
  }
  
  if (limit.count >= 20) { // 20 requests per minute
    return false
  }
  
  limit.count++
  return true
}
```

### 1.10 Context Enrichment Strategy

```typescript
const enrichContext = async (mcpClient: McpClient, userId: string) => {
  // Fetch user's recent activity via MCP
  const [recentProjects, activeTodos, recentQuestions] = await Promise.all([
    mcpClient.call('maix_search_projects', {
      authorId: userId,
      limit: 5,
      orderBy: 'updatedAt'
    }),
    mcpClient.call('maix_search_todos', {
      assigneeId: userId,
      status: ['TODO', 'IN_PROGRESS'],
      limit: 10
    }),
    mcpClient.call('maix_search_posts', {
      authorId: userId,
      type: 'QUESTION',
      limit: 5
    })
  ])
  
  return {
    recentProjects,
    activeTodos,
    recentQuestions,
    userCapabilities: determineUserCapabilities(userId)
  }
}
```

### 1.11 Simplified MVP Scope

#### Phase 1: Read-Only Assistant
- Search and display information
- Answer questions about the platform
- Navigate users to relevant pages
- No data modifications

#### Phase 2: Basic Write Operations
- Create projects with confirmation
- Simple project creation

#### Phase 3: Full MCP Integration
- All MCP tools available
- Complex workflows
- Multi-step operations
- Proactive suggestions

### 1.12 Testing Strategy

```typescript
// tests/mocks/mcpServer.ts
export const createMockMcpServer = () => {
  return {
    call: jest.fn((tool, params) => {
      switch(tool) {
        case 'maix_search_projects':
          return { projects: [] }
        case 'maix_manage_project':
          return { success: true, project: { id: '123' } }
        default:
          return { success: false, error: 'Unknown tool' }
      }
    })
  }
}
```

### 1.13 Proposed Simplification Options

**IMPORTANT**: These are OPTIONS to prevent over-engineering. Each must be explicitly ACCEPTED or REJECTED during the Align phase.

#### Simplification Option 1: No Conversation Persistence
- **Proposal**: Keep all conversations session-only, no database storage
- **Pros**: 
  - Eliminates privacy concerns
  - No database schema changes needed
  - Reduces storage costs
  - Simpler implementation (no conversation ID management)
- **Cons**: 
  - Users lose context on page refresh
  - Can't resume conversations later
  - No conversation history for debugging
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

#### Simplification Option 2: Single Model Only (Gemini Flash)
- **Proposal**: Use only gemini-1.5-flash, no model selection
- **Pros**:
  - 10x cheaper than Pro model
  - Faster responses (optimized for speed)
  - Simpler configuration
  - Predictable costs
- **Cons**:
  - Less capable for complex reasoning
  - May struggle with nuanced requests
  - No upgrade path without code changes
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

#### Simplification Option 3: No Streaming Responses
- **Proposal**: Return complete responses instead of streaming
- **Pros**:
  - Simpler client implementation
  - Easier error handling
  - No WebSocket/SSE complexity
  - Better for caching
- **Cons**:
  - Worse perceived performance
  - Users wait longer for first content
  - Less engaging UX
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

#### Simplification Option 4: Fixed Context Window (Last 5 Messages)
- **Proposal**: Only send last 5 message pairs to Gemini
- **Pros**:
  - Predictable token usage
  - Lower costs
  - Faster processing
  - Simpler context management
- **Cons**:
  - AI loses earlier context
  - May repeat questions
  - Less coherent long conversations
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

#### Simplification Option 5: No MCP Tool Explanations
- **Proposal**: AI never mentions which MCP tools it's using
- **Pros**:
  - Cleaner responses
  - Less technical jargon
  - Simpler prompt engineering
  - Users focus on outcomes not process
- **Cons**:
  - Less transparency
  - Harder to debug issues
  - Users can't learn the system
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

#### Simplification Option 6: No Caching Layer
- **Proposal**: Always fetch fresh data from MCP, no caching
- **Pros**:
  - Always up-to-date information
  - No cache invalidation complexity
  - Simpler architecture
  - Less memory usage
- **Cons**:
  - Higher latency
  - More MCP server load
  - Repeated identical queries
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

#### Simplification Option 7: No Rate Limiting Initially
- **Proposal**: Launch without rate limits, add if abused
- **Pros**:
  - Simpler initial implementation
  - Better user experience
  - No false positives blocking legitimate use
- **Cons**:
  - Risk of cost overruns
  - Potential for abuse
  - Harder to add retroactively
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

#### Simplification Option 8: No Custom Error Recovery
- **Proposal**: If MCP fails, show generic error message
- **Pros**:
  - Much simpler error handling
  - Consistent behavior
  - Less code to maintain
- **Cons**:
  - Worse user experience during failures
  - No graceful degradation
  - Users don't know what went wrong
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

#### Meta-Simplification: Start with ALL Simplifications
- **Proposal**: Accept all simplifications for MVP, add complexity only when proven necessary
- **Pros**:
  - Fastest path to working product
  - Learn from real usage
  - Avoid premature optimization
- **Cons**:
  - May disappoint early users
  - Technical debt if many need reversal
  - Could limit initial adoption
- **Awaiting Decision**: [ ] ACCEPT or [ ] REJECT

### 1.14 Open Questions for Alignment

#### Tier 1: Critical (Must answer before Plan phase)

1. **Q: Should AI Assistant have full MCP write access immediately?**
   - Option A: Start read-only, gradually add write access ✅ (RECOMMENDED)
   - Option B: Full access from day one (riskier)
   - **Awaiting Decision**

2. **Q: How should we handle MCP tool failures?**
   - Option A: Fail gracefully with user-friendly message
   - Option B: Retry with exponential backoff
   - Option C: Fallback to direct database queries (breaks abstraction)
   - **Awaiting Decision**

3. **Q: Should conversations persist across sessions?**
   - Option A: Session-only (simpler, more private) ✅ (RECOMMENDED)
   - Option B: Persist with user consent
   - Option C: Always persist (needs clear privacy policy)
   - **Awaiting Decision**

4. **Q: Monthly Gemini API budget?**
   - Affects model selection (flash vs pro)
   - Impacts rate limiting strategy
   - **Awaiting Decision**

#### Tier 2: Important

1. **Q: Should AI explain which MCP tools it's using?**
   - Transparency vs simplicity trade-off

2. **Q: How many conversation turns to keep in context?**
   - Token usage vs context quality

3. **Q: Should we cache MCP responses?**
   - Performance vs data freshness

#### Tier 3: Deferrable

1. **Q: Multi-language support?**
2. **Q: Voice input/output?**
3. **Q: Conversation export?**

### 1.15 Risk Mitigation

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| MCP server overload | Medium | High | Implement caching, rate limiting |
| PAT expiry during conversation | Low | Medium | Auto-refresh logic, graceful handling |
| Gemini API costs | Medium | High | Use flash model, implement quotas |
| MCP tool changes break AI | Medium | Medium | Version tool descriptions, regression tests |
| Security: Unauthorized MCP access | Low | Critical | Strict PAT validation, audit logging |

### 1.16 Success Metrics

1. **Functional Metrics**
   - MCP tool success rate > 95%
   - Response time < 3 seconds
   - PAT refresh success rate = 100%

2. **Usage Metrics**
   - Daily active AI users
   - MCP tools used per session
   - Conversation completion rate

3. **Quality Metrics**
   - User satisfaction score
   - Action accuracy (did AI use correct MCP tool?)
   - Context relevance score

### 1.17 Expert Review Results

[Expert review results included here...]

---

## 2. ALIGN PHASE - Awaiting Human Decisions

This section will be completed after human review of the Design phase.